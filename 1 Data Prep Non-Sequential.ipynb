{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "86c253c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/nielsen/churn/.venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# from tqdm import tqdm\n",
    "from tqdm.auto import tqdm\n",
    "from tqdm import tqdm\n",
    "\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b1d291ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1221309/2077797385.py:8: DtypeWarning: Columns (20) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_part3 = pd.read_csv(\"received_csvs/eierverifiseringer__historikk_part3.csv\")\n",
      "/tmp/ipykernel_1221309/2077797385.py:10: DtypeWarning: Columns (20) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_part5 = pd.read_csv(\"received_csvs/eierverifiseringer__historikk_part5.csv\")\n"
     ]
    }
   ],
   "source": [
    "abonnementsprodukter__historikk_df = pd.read_csv(\n",
    "    \"received_csvs/abonnementsprodukter__historikk.csv\"\n",
    ")\n",
    "\n",
    "\n",
    "df_part1 = pd.read_csv(\"received_csvs/eierverifiseringer__historikk_part1.csv\")\n",
    "df_part2 = pd.read_csv(\"received_csvs/eierverifiseringer__historikk_part2.csv\")\n",
    "df_part3 = pd.read_csv(\"received_csvs/eierverifiseringer__historikk_part3.csv\")\n",
    "df_part4 = pd.read_csv(\"received_csvs/eierverifiseringer__historikk_part4.csv\")\n",
    "df_part5 = pd.read_csv(\"received_csvs/eierverifiseringer__historikk_part5.csv\")\n",
    "df_part6 = pd.read_csv(\"received_csvs/eierverifiseringer__historikk_part6.csv\")\n",
    "eierverifiseringer__historikk_df = pd.concat(\n",
    "    [df_part1, df_part2, df_part3, df_part4, df_part5, df_part6], ignore_index=True\n",
    ")\n",
    "\n",
    "produktuttak_df = pd.read_csv(\"received_csvs/produktuttak.csv\")\n",
    "stg_dynamics__contacts_df = pd.read_csv(\"received_csvs/stg_dynamics__contacts.csv\")\n",
    "nps_svar_df = pd.read_csv(\"received_csvs/nps_svar.csv\").drop(columns=\"contact_rk.1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "82308a77",
   "metadata": {},
   "outputs": [],
   "source": [
    "abonnementsprodukter__historikk_df.rename(\n",
    "    columns={\"subscriptionitem__contact_rk\": \"contact_rk\"}, inplace=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fb3f8c91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10444260"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(eierverifiseringer__historikk_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08b471a2",
   "metadata": {},
   "source": [
    "### Only store rows with valid membership"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7700dcb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "eierverifiseringer__historikk_df = eierverifiseringer__historikk_df[\n",
    "    eierverifiseringer__historikk_df[\"contact_rk\"].isin(\n",
    "        abonnementsprodukter__historikk_df[\"contact_rk\"]\n",
    "    )\n",
    "]\n",
    "produktuttak_df = produktuttak_df[\n",
    "    produktuttak_df[\"contact_rk\"].isin(abonnementsprodukter__historikk_df[\"contact_rk\"])\n",
    "]\n",
    "stg_dynamics__contacts_df = stg_dynamics__contacts_df[\n",
    "    stg_dynamics__contacts_df[\"contact_rk\"].isin(\n",
    "        abonnementsprodukter__historikk_df[\"contact_rk\"]\n",
    "    )\n",
    "]\n",
    "nps_svar_df = nps_svar_df[\n",
    "    nps_svar_df[\"contact_rk\"].isin(abonnementsprodukter__historikk_df[\"contact_rk\"])\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ca363617",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7684725"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(eierverifiseringer__historikk_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e874ad74",
   "metadata": {},
   "source": [
    "# Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dffbd3bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of NaNs:\n",
      "innmeldingsdato    102811\n",
      "startdato               0\n",
      "sluttdato          524027\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Count NaNs in specific columns\n",
    "nan_counts = (\n",
    "    abonnementsprodukter__historikk_df[[\"innmeldingsdato\", \"startdato\", \"sluttdato\"]]\n",
    "    .isna()\n",
    "    .sum()\n",
    ")\n",
    "\n",
    "print(\"Number of NaNs:\")\n",
    "print(nan_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "85cdd3d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of non-unique contact_rk: 0\n",
      "Series([], Name: count, dtype: int64)\n"
     ]
    }
   ],
   "source": [
    "# Find duplicated contact_rk values\n",
    "duplicates = stg_dynamics__contacts_df[\"contact_rk\"].value_counts().loc[lambda x: x > 1]\n",
    "\n",
    "# Display how many contact_rk are duplicated\n",
    "print(f\"Number of non-unique contact_rk: {duplicates.shape[0]}\")\n",
    "\n",
    "# If you want to see the list:\n",
    "print(duplicates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "29c1daac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows with age NaN dropped:\n",
      " age    58195\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "abonnementsprodukter__historikk_df = abonnementsprodukter__historikk_df.dropna(\n",
    "    subset=[\"sluttdato\"]\n",
    ")\n",
    "abonnementsprodukter__historikk_df = abonnementsprodukter__historikk_df.drop(\n",
    "    columns=[\"innmeldingsdato\", \"avtale_antall_år\"]\n",
    ")\n",
    "nan_count = stg_dynamics__contacts_df[[\"age\"]].isna().sum()\n",
    "stg_dynamics__contacts_df = stg_dynamics__contacts_df.dropna(subset=[\"age\"])\n",
    "\n",
    "print(\"Rows with age NaN dropped:\\n\", nan_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "05bf8720",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['registreringsnummer', 'status_kode_id', 'contact_rk',\n",
       "       'ownerverification__vehicle_rk', 'vehicle_rk', 'merke', 'modell',\n",
       "       'modelltype', 'kjøretøytype', 'drivstoff', 'girkasse', 'status',\n",
       "       'antall_aksler', 'antall_passasjerer', 'slagvolum_ccm', 'slagvolum_l',\n",
       "       'motoreffekt_hk', 'årsmodell', 'antall_år_registrert_på_eier',\n",
       "       'vraket_dato', 'er_importert', 'forrige_eu_kontroll_dato',\n",
       "       'neste_eu_kontroll_dato', 'registert_første_gang_dato'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eierverifiseringer__historikk_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe51bc7e",
   "metadata": {},
   "source": [
    "# Data processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6333801c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing contacts: 100%|██████████| 431462/431462 [04:40<00:00, 1538.30it/s]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from dateutil.relativedelta import relativedelta\n",
    "\n",
    "df = abonnementsprodukter__historikk_df.copy()\n",
    "df[\"startdato\"] = pd.to_datetime(df[\"startdato\"], errors=\"coerce\")\n",
    "df[\"sluttdato\"] = pd.to_datetime(df[\"sluttdato\"], errors=\"coerce\")\n",
    "df = df.dropna(subset=[\"startdato\", \"sluttdato\"])\n",
    "\n",
    "\n",
    "# make sure each contact is sorted\n",
    "df = df.sort_values([\"contact_rk\", \"startdato\"])\n",
    "\n",
    "\n",
    "# define the two product‐keys\n",
    "young_code = \"<redacted>\"\n",
    "reg_code = \"<redacted>\"\n",
    "\n",
    "# rebuild one “row per contact” (merging the 2 if they qualify)\n",
    "records = []\n",
    "for contact, grp in tqdm(\n",
    "    df.groupby(\"contact_rk\"), desc=\"Processing contacts\", mininterval=0.1\n",
    "):\n",
    "    has_y = young_code in grp[\"subscriptionitem__dynamics_product_rk\"].values\n",
    "    has_r = reg_code in grp[\"subscriptionitem__dynamics_product_rk\"].values\n",
    "\n",
    "    # merge case\n",
    "    if has_y and has_r:\n",
    "        y = (\n",
    "            grp[grp[\"subscriptionitem__dynamics_product_rk\"] == young_code]\n",
    "            .sort_values(\"startdato\")\n",
    "            .iloc[-1]\n",
    "        )\n",
    "        r = (\n",
    "            grp[grp[\"subscriptionitem__dynamics_product_rk\"] == reg_code]\n",
    "            .sort_values(\"startdato\")\n",
    "            .iloc[0]\n",
    "        )\n",
    "\n",
    "        if (r[\"startdato\"] - y[\"sluttdato\"]).days <= 365:\n",
    "            merged = r.copy()\n",
    "            merged[\"startdato\"] = y[\"startdato\"]\n",
    "            merged[\"sluttdato\"] = r[\"sluttdato\"]\n",
    "            merged[\"regular_start\"] = r[\"startdato\"]\n",
    "            merged[\"young_to_regular\"] = True  # <— flag it\n",
    "            records.append(merged)\n",
    "            continue\n",
    "\n",
    "    # all other cases\n",
    "    for _, row in grp.iterrows():\n",
    "        r2 = row.copy()\n",
    "        r2[\"regular_start\"] = (\n",
    "            r2[\"startdato\"]\n",
    "            if r2[\"subscriptionitem__dynamics_product_rk\"] == reg_code\n",
    "            else pd.NaT\n",
    "        )\n",
    "        r2[\"young_to_regular\"] = False  # <— no merge\n",
    "        records.append(r2)\n",
    "\n",
    "df2 = pd.DataFrame(records)\n",
    "\n",
    "# feature‐engineering\n",
    "# precompute who ever had each type\n",
    "contact_codes = df.groupby(\"contact_rk\")[\"subscriptionitem__dynamics_product_rk\"].agg(\n",
    "    set\n",
    ")\n",
    "\n",
    "had_young = contact_codes.map(lambda s: young_code in s)\n",
    "had_regular = contact_codes.map(lambda s: reg_code in s)\n",
    "\n",
    "df2[\"had_young_member_flag\"] = df2[\"contact_rk\"].map(\n",
    "    lambda x: True if had_young[x] else False\n",
    ")\n",
    "\n",
    "df2[\"only_young\"] = df2[\"contact_rk\"].map(lambda x: had_young[x] and not had_regular[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "059c4118",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute “prev_end” and gap\n",
    "df2[\"prev_end\"] = df2.groupby(\"contact_rk\")[\"sluttdato\"].shift()\n",
    "df2[\"gap\"] = (df2[\"startdato\"] - df2[\"prev_end\"]).dt.days.fillna(-1).astype(int)\n",
    "\n",
    "# Flag new member-instance when gap > 365 or first record\n",
    "df2[\"new_instance\"] = df2[\"gap\"] > 365\n",
    "\n",
    "# Instance index per contact\n",
    "df2[\"instance_idx\"] = df2.groupby(\"contact_rk\")[\"new_instance\"].cumsum()\n",
    "\n",
    "# Aggregate per (contact_rk, instance_idx)\n",
    "agg = {\n",
    "    \"startdato\": \"min\",\n",
    "    \"sluttdato\": \"max\",\n",
    "    \"gap\": \"first\",\n",
    "}\n",
    "df_agg = df2.groupby([\"contact_rk\", \"instance_idx\"]).agg(agg).reset_index()\n",
    "\n",
    "# Churn metrics\n",
    "df_agg[\"churn_count\"] = df_agg[\"instance_idx\"]\n",
    "df_agg[\"last_churn_gap\"] = df_agg[\"gap\"].where(df_agg[\"instance_idx\"] > 1, -1)\n",
    "\n",
    "# Create a new contact_rk identifier per instance\n",
    "df_agg[\"contact_rk_new\"] = (\n",
    "    df_agg[\"contact_rk\"].astype(str) + \"_\" + df_agg[\"instance_idx\"].astype(str)\n",
    ")\n",
    "\n",
    "# Merge back instance-related fields to original df\n",
    "df2 = df2.merge(\n",
    "    df_agg[\n",
    "        [\n",
    "            \"contact_rk\",\n",
    "            \"instance_idx\",\n",
    "            \"churn_count\",\n",
    "            \"last_churn_gap\",\n",
    "            \"contact_rk_new\",\n",
    "        ]\n",
    "    ],\n",
    "    on=[\"contact_rk\", \"instance_idx\"],\n",
    "    how=\"left\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8c3c182",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 534585/534585 [01:44<00:00, 5129.40it/s]\n"
     ]
    }
   ],
   "source": [
    "# Calculate adjusted_date and target\n",
    "def calculate_adjusted_date_and_target(row):\n",
    "    start = row[\"startdato\"]\n",
    "    end = row[\"sluttdato\"]\n",
    "\n",
    "    # Duration in days\n",
    "    duration = (end - start).days\n",
    "\n",
    "    # Define year thresholds\n",
    "    one_year_3_weeks = 365 + 21\n",
    "    two_years_3_weeks = 2 * 365 + 21\n",
    "    three_years_3_weeks = 3 * 365 + 21\n",
    "\n",
    "    # Valid target options\n",
    "    valid_choices = [0]\n",
    "    if duration >= one_year_3_weeks:\n",
    "        valid_choices.append(1)\n",
    "    if duration >= two_years_3_weeks:\n",
    "        valid_choices.append(2)\n",
    "\n",
    "    years_to_subtract = np.random.choice(valid_choices)\n",
    "\n",
    "    # Anchor to Feb 2nd of the end year, then subtract years\n",
    "    adjusted_base = pd.Timestamp(year=end.year, month=2, day=2)\n",
    "    adjusted_date = adjusted_base - relativedelta(years=years_to_subtract)\n",
    "\n",
    "    return pd.Series(\n",
    "        [adjusted_date, years_to_subtract], index=[\"adjusted_date\", \"target\"]\n",
    "    )\n",
    "\n",
    "\n",
    "df2[[\"adjusted_date\", \"target\"]] = df2.progress_apply(\n",
    "    calculate_adjusted_date_and_target, axis=1\n",
    ")\n",
    "\n",
    "# Handle adjusted_date < startdato\n",
    "# Drop these rows\n",
    "df2 = df2[df2[\"adjusted_date\"] >= df2[\"startdato\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7359e84f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 449483/449483 [01:13<00:00, 6132.56it/s]\n"
     ]
    }
   ],
   "source": [
    "# Calculate membership duration\n",
    "def calculate_membership_duration(row):\n",
    "    start = row[\"startdato\"]\n",
    "    adjusted = row[\"adjusted_date\"]\n",
    "    delta = relativedelta(adjusted, start)\n",
    "    full_years = delta.years\n",
    "    total_days = (adjusted - start).days\n",
    "    return pd.Series(\n",
    "        [full_years, total_days], index=[\"membership_years\", \"membership_days\"]\n",
    "    )\n",
    "\n",
    "\n",
    "# now ONLY compute days_since_regular on the merged rows:\n",
    "df2[\"days_since_regular\"] = np.where(\n",
    "    df2[\"young_to_regular\"],\n",
    "    (df2[\"adjusted_date\"] - df2[\"regular_start\"]).dt.days,\n",
    "    -1,\n",
    ")\n",
    "\n",
    "df2[[\"membership_years\", \"membership_days\"]] = df2.progress_apply(\n",
    "    calculate_membership_duration, axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "84c47c88",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df2.drop(\n",
    "    columns=[\n",
    "        \"prev_end\",\n",
    "        \"regular_start\",\n",
    "        \"subscriptionitem__dynamics_product_rk\",\n",
    "        \"instance_idx\",\n",
    "        \"new_instance\",\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5560e6ba",
   "metadata": {},
   "source": [
    "# Vehicle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c842b216",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "price_dict = {}\n",
    "\n",
    "with open(\"car_mapping_final.json\", \"r\") as f:\n",
    "    price_dict = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "681444f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/nielsen/churn/.venv/lib/python3.11/site-packages/numpy/_core/fromnumeric.py:3904: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/root/nielsen/churn/.venv/lib/python3.11/site-packages/numpy/_core/_methods.py:147: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "100%|██████████| 7684725/7684725 [01:35<00:00, 80173.18it/s]\n",
      "100%|██████████| 7684725/7684725 [01:30<00:00, 84902.12it/s]\n"
     ]
    }
   ],
   "source": [
    "df_car = eierverifiseringer__historikk_df.copy()\n",
    "\n",
    "# Compute average price for each car entry\n",
    "average_prices = {k: np.mean(v) for k, v in price_dict.items()}\n",
    "\n",
    "\n",
    "def simplify_modell(modell):\n",
    "    if pd.isnull(modell):\n",
    "        return \"\"\n",
    "    return modell.strip().split()[0]\n",
    "\n",
    "\n",
    "df_car[\"simplified_modell\"] = df_car[\"modell\"].apply(simplify_modell)\n",
    "\n",
    "\n",
    "# Adjust the make_price_key function to use the simplified model\n",
    "def make_price_key(row):\n",
    "    try:\n",
    "        return f\"{row['merke'].strip()} {row['simplified_modell']} {row['drivstoff'].strip()} {int(row['årsmodell'])}\"\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "\n",
    "df_car[\"price_key\"] = df_car.progress_apply(make_price_key, axis=1)\n",
    "\n",
    "\n",
    "# Define depreciation function\n",
    "def estimate_original_price_piecewise(row):\n",
    "    key = row[\"price_key\"]\n",
    "    years = row[\"antall_år_registrert_på_eier\"]\n",
    "\n",
    "    if key not in average_prices or pd.isnull(years):\n",
    "        return -1\n",
    "\n",
    "    current_price = average_prices[key]\n",
    "\n",
    "    if years < 1:\n",
    "        return -1  # not enough info\n",
    "\n",
    "    elif years == 1:\n",
    "        return round(current_price / 0.80, 2)\n",
    "    elif years == 2:\n",
    "        return round(current_price / 0.70, 2)\n",
    "    elif years == 3:\n",
    "        return round(current_price / 0.60, 2)\n",
    "    elif years == 4:\n",
    "        return round(current_price / 0.54, 2)\n",
    "    elif years == 5:\n",
    "        return round(current_price / 0.486, 2)\n",
    "    elif years >= 6:\n",
    "        decay_factor = 0.486 * (0.90 ** (years - 5))\n",
    "        return round(current_price / decay_factor, 2)\n",
    "\n",
    "    return -1\n",
    "\n",
    "\n",
    "# Apply estimation\n",
    "df_car[\"estimated_first_owner_price\"] = df_car.progress_apply(\n",
    "    estimate_original_price_piecewise, axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "73e37a00",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_car = df_car.drop(\n",
    "    columns=[\n",
    "        \"modelltype\",\n",
    "        \"kjøretøytype\",\n",
    "        \"antall_aksler\",\n",
    "        \"slagvolum_ccm\",\n",
    "        \"slagvolum_l\",\n",
    "        \"price_key\",\n",
    "        \"simplified_modell\",\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32f32abc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Ensure the dates are datetimes\n",
    "df_car[\"neste_eu_kontroll_dato\"] = pd.to_datetime(\n",
    "    df_car[\"neste_eu_kontroll_dato\"], errors=\"coerce\"\n",
    ")\n",
    "\n",
    "# Bring membership_years onto the car table\n",
    "df_car2 = df_car.merge(\n",
    "    df2[[\"contact_rk\", \"target\"]],\n",
    "    on=\"contact_rk\",\n",
    "    how=\"right\",  # keep contacts even if they have zero cars\n",
    "    indicator=True,  # so we know who had no cars at all\n",
    ")\n",
    "\n",
    "# Filter out ineligible cars\n",
    "df_car2 = df_car2[df_car2[\"antall_år_registrert_på_eier\"] <= df_car2[\"target\"]]\n",
    "\n",
    "# Calculate days until next EU-kontroll\n",
    "df_car2[\"days_to_eu\"] = (\n",
    "    df_car2[\"neste_eu_kontroll_dato\"].sub(pd.Timestamp.now()).dt.days\n",
    ")\n",
    "\n",
    "# Compute per-contact summaries\n",
    "#  5a) Count of valid cars\n",
    "count = df_car2.groupby(\"contact_rk\").size().rename(\"num_cars\")\n",
    "\n",
    "#  Identify the row-index of the car with the max årsmodell\n",
    "idx_max = df_car2.groupby(\"contact_rk\")[\"årsmodell\"].idxmax()\n",
    "\n",
    "#  Pull out that “latest” car’s details\n",
    "latest = (\n",
    "    df_car2.loc[idx_max]\n",
    "    .set_index(\"contact_rk\", drop=False)[\n",
    "        [\n",
    "            \"merke\",\n",
    "            \"modell\",\n",
    "            \"drivstoff\",\n",
    "            \"girkasse\",\n",
    "            \"antall_passasjerer\",\n",
    "            \"motoreffekt_hk\",\n",
    "            \"årsmodell\",\n",
    "            \"antall_år_registrert_på_eier\",\n",
    "            \"days_to_eu\",\n",
    "            \"estimated_first_owner_price\",\n",
    "        ]\n",
    "    ]\n",
    "    .rename(\n",
    "        columns={\n",
    "            \"merke\": \"latest_merke\",\n",
    "            \"modell\": \"latest_modell\",\n",
    "            \"drivstoff\": \"latest_drivstoff\",\n",
    "            \"girkasse\": \"latest_girkasse\",\n",
    "            \"antall_passasjerer\": \"latest_antall_passasjerer\",\n",
    "            \"motoreffekt_hk\": \"latest_motoreffekt_hk\",\n",
    "            \"årsmodell\": \"latest_årsmodell\",\n",
    "            \"antall_år_registrert_på_eier\": \"latest_antall_år_registrert_på_eier\",\n",
    "            \"days_to_eu\": \"days_to_neste_eu_kontroll_dato\",\n",
    "            \"estimated_first_owner_price\": \"estimated_first_owner_price\",\n",
    "        }\n",
    "    )\n",
    ")\n",
    "\n",
    "# Merge summaries back into df2\n",
    "df2_merged = (\n",
    "    df2.set_index(\"contact_rk\")\n",
    "    .join(count, how=\"left\")\n",
    "    .join(latest, how=\"left\")\n",
    "    .fillna({\"num_cars\": 0})  # contacts with no eligible cars get zero\n",
    "    .reset_index()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "64d54a78",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2_merged[\"latest_antall_år_registrert_på_eier\"] = (\n",
    "    df2_merged[\"latest_antall_år_registrert_på_eier\"] - df2_merged[\"target\"]\n",
    ").clip(lower=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e8f1b94a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['contact_rk', 'subscriptionitem_rk', 'er_husstandsmedlem', 'startdato',\n",
       "       'sluttdato', 'young_to_regular', 'had_young_member_flag', 'only_young',\n",
       "       'gap', 'churn_count', 'last_churn_gap', 'contact_rk_new',\n",
       "       'adjusted_date', 'target', 'days_since_regular', 'membership_years',\n",
       "       'membership_days', 'num_cars', 'latest_merke', 'latest_modell',\n",
       "       'latest_drivstoff', 'latest_girkasse', 'latest_antall_passasjerer',\n",
       "       'latest_motoreffekt_hk', 'latest_årsmodell',\n",
       "       'latest_antall_år_registrert_på_eier', 'days_to_neste_eu_kontroll_dato',\n",
       "       'estimated_first_owner_price'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2_merged.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ddf389f",
   "metadata": {},
   "source": [
    "# Produktuttak"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8910822",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure all your dates and amounts are the right dtype:\n",
    "produktuttak_df[\"avsluttet_dato\"] = pd.to_datetime(\n",
    "    produktuttak_df[\"avsluttet_dato\"], errors=\"coerce\"\n",
    ")\n",
    "produktuttak_df[\"beløp\"] = pd.to_numeric(produktuttak_df[\"beløp\"], errors=\"coerce\")\n",
    "df2_merged[\"adjusted_date\"] = pd.to_datetime(\n",
    "    df2_merged[\"adjusted_date\"], errors=\"coerce\"\n",
    ")\n",
    "\n",
    "# Bring adjusted_date onto the produktuttak table so you can filter per-row:\n",
    "pt = produktuttak_df.merge(\n",
    "    df2_merged[[\"contact_rk\", \"adjusted_date\"]], on=\"contact_rk\", how=\"inner\"\n",
    ")\n",
    "\n",
    "# Filter out any produktuttak where avsluttet_dato is on/after the adjusted_date:\n",
    "pt = pt[pt[\"avsluttet_dato\"] < pt[\"adjusted_date\"]]\n",
    "\n",
    "# Group & aggregate per contact:\n",
    "spend = (\n",
    "    pt.groupby(\"contact_rk\")\n",
    "    .agg(\n",
    "        total_spent=(\"beløp\", \"sum\"),\n",
    "        last_spent_date=(\"avsluttet_dato\", \"max\"),\n",
    "    )\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "# Compute days since that last spend:\n",
    "spend[\"days_since_last_spent\"] = (\n",
    "    pd.Timestamp.now().normalize()  # or use a fixed “today” if you prefer\n",
    "    - spend[\"last_spent_date\"]\n",
    ").dt.days\n",
    "\n",
    "# 6) Merge those two new columns back into df2_merged:\n",
    "df2_merged = df2_merged.merge(\n",
    "    spend[[\"contact_rk\", \"total_spent\", \"days_since_last_spent\"]],\n",
    "    on=\"contact_rk\",\n",
    "    how=\"left\",\n",
    ")\n",
    "\n",
    "df2_merged[\"total_spent\"] = df2_merged[\"total_spent\"].fillna(0)\n",
    "df2_merged[\"days_since_last_spent\"] = df2_merged[\"days_since_last_spent\"].fillna(-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84b60954",
   "metadata": {},
   "source": [
    "# Personal Info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f8cf3b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure date columns are datetimes\n",
    "stg_dynamics__contacts_df[\"birth_date\"] = pd.to_datetime(\n",
    "    stg_dynamics__contacts_df[\"birth_date\"], errors=\"coerce\"\n",
    ")\n",
    "df2_merged[\"adjusted_date\"] = pd.to_datetime(\n",
    "    df2_merged[\"adjusted_date\"], errors=\"coerce\"\n",
    ")\n",
    "\n",
    "# Merge in birth_date, gender, sentralitetsindex\n",
    "df2_merged = df2_merged.merge(\n",
    "    stg_dynamics__contacts_df[\n",
    "        [\"contact_rk\", \"birth_date\", \"gender\", \"sentralitetsindex\"]\n",
    "    ],\n",
    "    on=\"contact_rk\",\n",
    "    how=\"left\",\n",
    ")\n",
    "\n",
    "# Calculate age (in whole years) as of adjusted_date\n",
    "df2_merged[\"age\"] = (\n",
    "    (df2_merged[\"adjusted_date\"] - df2_merged[\"birth_date\"])\n",
    "    .dt.days.floordiv(365.25)\n",
    "    .astype(\"Int64\")  # nullable integer, if you want missing where birth_date is null\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d3794c5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original row count: 449483\n",
      "Remaining row count after filtering: 419432\n",
      "Number of rows dropped: 30051\n"
     ]
    }
   ],
   "source": [
    "# Original number of rows\n",
    "original_count = len(df2_merged)\n",
    "\n",
    "# Filter the DataFrame\n",
    "# df2_merged = df2_merged[(df2_merged['age'] >= 18) & (df2_merged['age'] <= 90)]\n",
    "df2_merged = df2_merged[\n",
    "    (df2_merged[\"age\"] >= 18) & (df2_merged[\"age\"] <= 90) & df2_merged[\"age\"].notna()\n",
    "]\n",
    "\n",
    "# Number of rows after filtering\n",
    "filtered_count = len(df2_merged)\n",
    "\n",
    "# Number of rows dropped\n",
    "dropped_count = original_count - filtered_count\n",
    "\n",
    "# Display the counts\n",
    "print(f\"Original row count: {original_count}\")\n",
    "print(f\"Remaining row count after filtering: {filtered_count}\")\n",
    "print(f\"Number of rows dropped: {dropped_count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "912b349a",
   "metadata": {},
   "source": [
    "# NPS Review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8c7e698",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure dates are datetimes\n",
    "nps_svar_df[\"opprettet_dato\"] = pd.to_datetime(\n",
    "    nps_svar_df[\"opprettet_dato\"], errors=\"coerce\"\n",
    ")\n",
    "df2_merged[\"adjusted_date\"] = pd.to_datetime(\n",
    "    df2_merged[\"adjusted_date\"], errors=\"coerce\"\n",
    ")\n",
    "\n",
    "# Bring adjusted_date onto the NPS table so we can filter per-row\n",
    "nps = nps_svar_df.merge(\n",
    "    df2_merged[[\"contact_rk\", \"adjusted_date\"]], on=\"contact_rk\", how=\"inner\"\n",
    ")\n",
    "\n",
    "# Keep only reviews that happened before adjusted_date\n",
    "nps = nps[nps[\"opprettet_dato\"] < nps[\"adjusted_date\"]]\n",
    "\n",
    "# Compute group-level aggregates\n",
    "agg = (\n",
    "    nps.groupby(\"contact_rk\")\n",
    "    .agg(\n",
    "        nps_mean=(\"score\", \"mean\"),\n",
    "        nps_median=(\"score\", \"median\"),\n",
    "        nps_count=(\"score\", \"size\"),\n",
    "        last_date=(\"opprettet_dato\", \"max\"),\n",
    "    )\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "# Pull out the score on that last_date (nps_latest)\n",
    "idx = nps.groupby(\"contact_rk\")[\"opprettet_dato\"].idxmax()\n",
    "latest = nps.loc[idx, [\"contact_rk\", \"score\"]].rename(columns={\"score\": \"nps_latest\"})\n",
    "\n",
    "# Merge mean/median/count/last_date with latest score\n",
    "nps_summary = agg.merge(latest, on=\"contact_rk\", how=\"left\")\n",
    "\n",
    "# Compute days since the last review\n",
    "nps_summary[\"days_since_nps\"] = (\n",
    "    (\n",
    "        nps_summary[\"adjusted_date\"]\n",
    "        if \"adjusted_date\" in nps_summary\n",
    "        else nps_summary.merge(\n",
    "            df2_merged[[\"contact_rk\", \"adjusted_date\"]], on=\"contact_rk\", how=\"left\"\n",
    "        )[\"adjusted_date\"]\n",
    "    )\n",
    "    .sub(nps_summary[\"last_date\"])\n",
    "    .dt.days\n",
    ")\n",
    "\n",
    "# Bring the summary into df2_merged\n",
    "df2_merged = df2_merged.merge(\n",
    "    nps_summary[\n",
    "        [\n",
    "            \"contact_rk\",\n",
    "            \"nps_mean\",\n",
    "            \"nps_median\",\n",
    "            \"nps_latest\",\n",
    "            \"nps_count\",\n",
    "            \"days_since_nps\",\n",
    "        ]\n",
    "    ],\n",
    "    on=\"contact_rk\",\n",
    "    how=\"left\",\n",
    ")\n",
    "\n",
    "# Fill in contacts with no reviews\n",
    "df2_merged[[\"nps_mean\", \"nps_median\", \"nps_latest\", \"days_since_nps\"]] = df2_merged[\n",
    "    [\"nps_mean\", \"nps_median\", \"nps_latest\", \"days_since_nps\"]\n",
    "].fillna(-1)\n",
    "\n",
    "df2_merged[\"nps_count\"] = df2_merged[\"nps_count\"].fillna(0).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "32f1c470",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['contact_rk', 'subscriptionitem_rk', 'er_husstandsmedlem', 'startdato',\n",
       "       'sluttdato', 'young_to_regular', 'had_young_member_flag', 'only_young',\n",
       "       'gap', 'churn_count', 'last_churn_gap', 'contact_rk_new',\n",
       "       'adjusted_date', 'target', 'days_since_regular', 'membership_years',\n",
       "       'membership_days', 'num_cars', 'latest_merke', 'latest_modell',\n",
       "       'latest_drivstoff', 'latest_girkasse', 'latest_antall_passasjerer',\n",
       "       'latest_motoreffekt_hk', 'latest_årsmodell',\n",
       "       'latest_antall_år_registrert_på_eier', 'days_to_neste_eu_kontroll_dato',\n",
       "       'estimated_first_owner_price', 'total_spent', 'days_since_last_spent',\n",
       "       'birth_date', 'gender', 'sentralitetsindex', 'age', 'nps_mean',\n",
       "       'nps_median', 'nps_latest', 'nps_count', 'days_since_nps'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2_merged.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b03e8775",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ml = df2_merged.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "31f0878a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ml = df_ml.drop(\n",
    "    columns=[\n",
    "        \"contact_rk\",\n",
    "        \"subscriptionitem_rk\",\n",
    "        \"startdato\",\n",
    "        \"sluttdato\",\n",
    "        \"adjusted_date\",\n",
    "        \"birth_date\",\n",
    "        \"contact_rk_new\",\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "690575ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['er_husstandsmedlem', 'young_to_regular', 'had_young_member_flag',\n",
       "       'only_young', 'gap', 'churn_count', 'last_churn_gap', 'target',\n",
       "       'days_since_regular', 'membership_years', 'membership_days', 'num_cars',\n",
       "       'latest_merke', 'latest_modell', 'latest_drivstoff', 'latest_girkasse',\n",
       "       'latest_antall_passasjerer', 'latest_motoreffekt_hk',\n",
       "       'latest_årsmodell', 'latest_antall_år_registrert_på_eier',\n",
       "       'days_to_neste_eu_kontroll_dato', 'estimated_first_owner_price',\n",
       "       'total_spent', 'days_since_last_spent', 'gender', 'sentralitetsindex',\n",
       "       'age', 'nps_mean', 'nps_median', 'nps_latest', 'nps_count',\n",
       "       'days_since_nps'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ml.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c258f1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ml.to_csv(\"df_ml.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
